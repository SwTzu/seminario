                

\section{Marco Conceptual}
\label{sc:MC}


\subsection{Definición y clasificación de las heridas crónicas en pie diabético}
Las heridas crónicas son lesiones que, a diferencia de las heridas agudas, no logran completar un proceso normal de cicatrización en los tiempos esperados. Típicamente, si una herida no muestra signos claros de cierre tras $\sim 4$ semanas, se considera crónica o de difícil cicatrización \cite{healthcare11020273}. Estas lesiones constituyen un serio problema de salud publica a nivel global, afectando a millones de personas y generando costos sanitarios elevados (por ejemplo, se estiman mas de 25 mil millones de dólares anuales solo en Estados Unidos) \cite{healthcare11020273}. En pacientes con diabetes mellitus, las \textbf{ulceras de pie diabético} destacan como una de las complicaciones crónicas mas frecuentes y graves; presentan alta incidencia, manejo terapéutico complejo, y tienden a la cronicidad con recidivas frecuentes. Ademas, implican un alto riesgo de infecciones severas que pueden culminar en amputaciones; de hecho, las ulceras de pie diabético son una de las principales causas de hospitalización prolongada y discapacidad permanente en personas diabeticas. La diabetes y otras comorbilidades (ej. obesidad, arteriopatías) contribuyen a interrumpir el proceso normal de cicatrización, por lo que estos pacientes son propensos a desarrollar heridas crónicas \cite{healthcare11020273}.
Desde el punto de vista clínico, las heridas crónicas se clasifican según su etiología y gravedad. Se incluyen, entre otras, las úlceras por presión, úlceras venosas y las úlceras neuropáticas o isquémicas del diabético. En el caso específico del pie diabético, existen sistemas de estadificación para graduar la severidad de la úlcera; por ejemplo, la clasificación de Wagner (grados 0 a 5) se emplea para describir la profundidad y extensión del daño tisular, desde lesiones superficiales limitadas a la epidermis (grado 1) hasta gangrena extensa que compromete todo el pie (grado 5) \cite{healthcare11020273}. Estas clasificaciones ayudan a orientar el manejo terapéutico y pronóstico de la herida. Sin embargo, cabe señalar que muchas de estas escalas clínicas (Wagner y otras) dependen de la apreciación del evaluador, introduciendo cierto grado de subjetividad en la determinación del estadio de la lesión. En resumen, las heridas crónicas –y en particular las úlceras diabéticas– representan un desafío sanitario por su alta prevalencia y severidad, requiriendo sistemas estandarizados para su clasificación y seguimiento.

\subsection{Proceso Fisiológico de Cicatrización}

La cicatrización normal de una herida ocurre a través de una serie de fases fisiológicas solapadas, durante las cuales el tejido lesionado es reemplazado por tejido reparado. En términos generales, se distinguen tres etapas principales \cite{ulcerasCicatrizacixF3nxDAlcerasnet}:
\begin{enumerate}
    \item \textbf{Fase inflamatoria}
    \begin{enumerate}
        \item Ocurre inmediatamente tras la lesión y se extiende por los primeros días (aprox. días 0 al 4). En esta etapa se detiene la hemorragia mediante vasoconstricción y formación de coágulo (hemostasia) y se desencadena la respuesta inflamatoria local. Llegan neutrófilos y macrófagos al lecho de la herida para eliminar bacterias y tejido dañado, limpiando la zona y liberando citocinas y factores de crecimiento que inician la reparación \cite{ulcerasCicatrizacixF3nxDAlcerasnet}. Esta fase prepara el terreno para la regeneración, pero en heridas complicadas puede prolongarse más de lo normal, especialmente si persisten factores irritantes o infección crónica.
    \end{enumerate}
    \item \textbf{Fase Proliferativa}
    \begin{enumerate}
        \item Es la etapa intermedia, típicamente abarcando desde  $\sim$ el día 4 hasta la segunda semana post-lesión.Durante esta fase se forma tejido de granulación que llena el defecto de la herida: prolifera nueva vasculatura (angiogénesis) y fibroblastos que depositan matriz extracelular y colágeno. A la par, ocurre la reepitelización, con migración y división de queratinocitos desde los bordes (y anexos cutáneos remanentes) para cubrir la superficie lesionada. También se inicia la contracción de la herida gracias a miofibroblastos, acercando los bordes para reducir el área abierta \cite{ulcerasCicatrizacixF3nxDAlcerasnet}. Esta fase proliferativa es crucial para cerrar la herida; su eficacia determina en gran medida el pronóstico de cicatrización.
    \end{enumerate}
    \item \textbf{Fase de maduración (remodelación)}
    \begin{enumerate}
        \item Es la fase final, que puede prolongarse por meses luego de cerrada la herida. En esta etapa el nuevo tejido conectivo se reorganiza y refuerza: las fibras de colágeno tipo III depositadas en granulación se remodelan a colágeno tipo I más resistente, aumentando gradualmente la fuerza tensil de la cicatriz. Los vasos sanguíneos neoformados en exceso involucionan y la inflamación residual desaparece, quedando una cicatriz más pálida y firme. Aunque la herida luzca cerrada, internamente continúa este remodelado que puede durar de 6 a 12 meses (dependiendo del tamaño y profundidad de la lesión).
    \end{enumerate}
\end{enumerate}


\subsection{Evaluación Clínica de las heridas y escalas existentes}

La evaluación clínica tradicional de las heridas se basa predominantemente en la inspección visual y mediciones manuales, lo cual introduce un componente subjetivo significativo. Por ejemplo, el método clásico para medir el tamaño de una úlcera es usando una regla para longitud/ancho y una sonda o hisopo para estimar la profundidad; sin embargo, este método es laborioso, poco preciso para áreas irregulares y conlleva riesgo de introducir infección al contacto con la herida \cite{healthcare11020273}. Adicionalmente, la apreciación de aspectos cualitativos –como el tipo de tejido presente o el grado de humedad/exudado– depende del criterio del profesional. Esto genera variabilidad \textbf{inter e intra-observador:} distintos clínicos pueden estimar porcentajes de tejido de granulación vs. necrótico de forma diferente, llevando a inconsistencias diagnósticas y diferencias en decisiones terapéuticas. De hecho, la literatura reporta que la evaluación visual de heridas ulcerosas es altamente subjetiva, pudiendo retrasar intervenciones óptimas si se subestima la severidad de la lesión.

Para mejorar la objetividad y estandarización, se han desarrollado herramientas y escalas de evaluación de heridas. Una de ellas es la \textbf{Bates-Jensen Wound Assessment Tool (BWAT)} \cite{harris2010bates}, anteriormente conocida como escala PSST, que evalúa clínicamente múltiples parámetros de la herida (tamaño, profundidad, bordes, tipo de tejido, exudado, etc.) asignando puntuaciones que reflejan el estado de cicatrización. Otra escala común es la \textbf{Pressure Ulcer Scale for Healing (PUSH)} \cite{stotts2001instrument}, enfocada en úlceras por presión, que monitoriza la evolución mediante un puntaje derivado de área, cantidad de exudado y tipo de tejido predominante. En el contexto de la documentación fotográfica, destaca el \textbf{Photographic Wound Assessment Tool (PWAT)} \cite{Curti2024}, una herramienta específica para evaluar heridas a partir de fotografías estandarizadas. El PWAT cuantifica ocho dominios (tamaño de la herida, profundidad/compromiso de tejidos, tipo de tejido necrótico, cantidad de tejido necrótico, tipo de tejido de granulación, cantidad de granulación, condición de los bordes y condición de la piel perilesional) otorgando a cada uno un sub-puntaje; la suma total varía de 0 (herida cerrada) a 32 (herida de peor aspecto). Esta escala fotográfica permite un seguimiento objetivo de la cicatrización: una disminución del puntaje PWAT en sucesivas evaluaciones indica que la herida está sanando. En teoría, el PWAT reduce la subjetividad al ofrecer descripciones precisas para cada categoría de puntaje (por ejemplo, define criterios claros para “tipo de tejido necrótico” o “viabilidad de la piel periférica”).

Pese a la existencia de estas escalas estandarizadas, su implementación práctica presenta limitaciones. Aplicar herramientas como BWAT o PWAT requiere tiempo adicional en clínica para realizar la puntuación, y cierta capacitación del personal para usarlas consistentemente. En entornos de alta demanda asistencial, a veces se omite el uso sistemático de estas escalas, manteniéndose evaluaciones más bien cualitativas. Además, no eliminan por completo la subjetividad –por ejemplo, dos profesionales podrían discrepar ligeramente en la interpretación de “\% de tejido necrótico” en una foto al usar PWAT, aunque la escala delimite rangos. De hecho, incluso con apoyo de imágenes, sigue habiendo variabilidad entre evaluadores humanos. Otra barrera es la actualización y registro de estos puntajes en historias clínicas, que puede ser percibido como trabajo administrativo extra.

En la práctica clínica diaria, \textbf{la clasificación del pie diabético} a menudo combina herramientas: se usa la clasificación de Wagner para grado de la úlcera, y escalas de riesgo de úlceras por presión (Braden, Norton) si el paciente está encamado, junto con inspecciones seriadas de la herida para evaluar signos de mejoría o deterioro (disminución de tamaño, aumento de tejido granulado, etc.). No obstante, dada la subjetividad inherente, se reconoce la necesidad de \textbf{métodos más objetivos y automáticos} para evaluar las heridas ulcerosas de forma más confiable. En años recientes se han introducido dispositivos y aplicaciones móviles que ayudan a medir digitalmente las heridas: por ejemplo, sistemas de fotografía con calibración que calculan el área de la lesión a partir de la imagen
. Algunos de estos incluso diferencian áreas de tejido dentro de la herida, aunque pueden requerir que el usuario marque manualmente puntos de referencia o delimite aproximadamente la zona de interés para cada tejido
. Si bien estas tecnologías han aliviado algunas limitaciones (p.ej. eliminan el contacto físico con la herida durante la medición
), \textbf{aún no están ampliamente difundidas}, y muchas dependen de hardware específico o condiciones controladas. Esto sienta el escenario para la incursión de técnicas de inteligencia artificial, que prometen automatizar completamente la evaluación de heridas a partir de imágenes, reduciendo la dependencia en la subjetividad humana.

\subsection{Aplicaciones de inteligencia artificial en el análisis de imágenes de heridas}

En la última década, la inteligencia artificial (IA) –especialmente las técnicas de deep learning o aprendizaje profundo– ha irrumpido en el campo del análisis de imágenes médicas, incluyendo el cuidado de heridas. El objetivo es asistir o automatizar tareas como la medición del tamaño de la herida, la segmentación de los distintos tejidos en la úlcera y la estimación del estadio de cicatrización, todo a partir de fotografías digitales. Diversos estudios recientes han explorado enfoques de IA para superar las deficiencias del método manual de la regla, con resultados prometedores
. De hecho, Chairat  (2023) señalan que la IA tiene el potencial de proporcionar mediciones objetivas y precisas de características clave de la herida (área, proporción de tejidos, etc.), sirviendo como base para una evaluación y planificación de tratamiento más informada
. En esencia, un sistema de IA bien entrenado podría fungir como una “segunda opinión” automatizada, cuantificando la herida de forma consistente en cada control.

\textbf{D. M. Anisuzzaman  (2020)} llevaron a cabo una \textbf{revisión sistemática} exhaustiva sobre el uso de inteligencia artificial basada en imágenes para la evaluación de heridas \cite{https://doi.org/10.48550/arxiv.2009.07141}. En dicha revisión se recopiló y analizó más de un centenar de estudios relevantes, cubriendo tanto métodos de \textbf{medición/segmentación} de heridas como técnicas de \textbf{diagnóstico/clasificación} automatizada, además de sistemas integrales (incluyendo hardware especializado, software y aplicaciones móviles) desarrollados hasta la fecha.

Los hallazgos de Anisuzzaman  muestran que las aproximaciones de IA aplicadas a heridas han evolucionado desde algoritmos relativamente simples (basados en reglas fijas de procesamiento de la imagen) hasta modelos complejos de aprendizaje profundo. Inicialmente, varios trabajos emplearon métodos \textbf{basados en reglas o algoritmos de visión tradicionales}, por ejemplo, segmentación por umbral de color o clustering (agrupamiento) de pixeles para distinguir áreas de la herida.

Posteriormente, se introdujeron técnicas de \textbf{aprendizaje automático clásico}: clasificadores como support vector machines (SVM) o árboles de decisión que, usando características extraídas de la imagen (p.ej., estadísticas de color o textura), intentaban distinguir entre heridas que cicatrizan bien vs. mal, o entre distintos tipos de lesiones \cite{Curti2024}. En años recientes, el auge del \textbf{aprendizaje profundo} ha llevado a que predominen los modelos de \textbf{redes neuronales convolucionales (CNN)} entrenados de extremo a extremo con grandes conjuntos de imágenes de heridas. Estos modelos aprenden directamente de los píxeles a segmentar y clasificar, muchas veces superando el desempeño de las técnicas anteriores al poder captar patrones más complejos

Ejemplo de lo anterior es el trabajo de \textbf{Sawrawit Chairat  (2023)}, quienes desarrollaron un sistema automático de evaluación de heridas mediante algoritmos de \textit{deep learning}. En su estudio, emplearon arquitecturas de segmentación tipo \textbf{U-Net} combinadas con redes pre-entrenadas (EfficientNet-B2 y MobileNetV2) para analizar imágenes de úlceras capturadas con smartphones \cite{healthcare11020273}. El sistema de Chairat  integra además una etapa previa de \textbf{calibración de color y tamaño} usando una carta de calibración física colocada junto a la herida, lo que permite corregir diferencias de iluminación y escala entre fotografías. Los modelos de \textit{deep learning} así entrenados fueron capaces de \textbf{segmentar automáticamente} tanto el contorno del área total de la herida como las regiones correspondientes a tejido de granulación, tejido necrótico y área epitelial en cada imagen. 
Los resultados reportados indican una precisión elevada en algunos componentes: el mejor modelo logró un Índice de Jaccard (IoU) de  $\sim 0,70$ para la segmentación del área de la herida y  $\sim 0,64$ para la del tejido de granulación, lo que implica buena concordancia con lo delineado por expertos humanos \cite{Shi2014}. 
En cambio, el desempeño fue más moderado para la zona de epitelización (IoU  $\sim 0,40$) y bajo para áreas necróticas (IoU  $\sim 0,16$), evidenciando la mayor dificultad de la IA para identificar tejidos minoritarios o poco diferenciados en las imágenes. Aun con esas limitaciones, la herramienta demostró poder replicar de forma consistente las mediciones que usualmente realizan manualmente los clínicos, especialmente en lo referente al tamaño de la herida y al porcentaje de tejido de granulación. Los autores destacaron además que la incorporación de la carta de calibración mejoró el rendimiento del algoritmo, al estandarizar los colores y dimensiones en las fotos analizadas. Esto subraya la importancia de controlar las variables de imagen (iluminación, distancia, etc.) al aplicar IA en entornos clínicos reales.

Otro avance notable es el de \textbf{Curti}, quienes propusieron un sistema automatizado enfocado en \textbf{predecir la puntuación PWAT} de una herida a partir de la imagen. En este enfoque, se combina la segmentación automática con análisis de características (\textit{radiomics}): primero, una red neuronal identifica y delimita la herida en la fotografía; luego, sobre esa región, se extraen múltiples descriptores texturales y morfológicos diseñados para imitar los criterios que tendría un clínico al evaluar la herida (por ejemplo, rasgos que reflejan cantidad de tejido de granulación, presencia de bordes epiteliales, etc.). Finalmente, un modelo de regresión utiliza esas características para \textbf{estimar el puntaje PWAT} que correspondería a la imagen. Este sistema fue entrenado y validado con un amplio conjunto de imágenes anotadas por expertos, logrando resultados muy positivos: la puntuación PWAT predicha por la IA tuvo una correlación de alrededor de r = 0,85 (Spearman) con la puntuación otorgada por dermatólogos en imágenes de prueba no vistas por el modelo. En otras palabras, el algoritmo replicó en gran medida la evaluación humana, lo que proporciona un benchmark alentador para futuras aplicaciones de IA en este campo. Cabe destacar que los autores enfatizan que las características utilizadas por el modelo son fácilmente interpretables por clínicos (tienen un significado médico claro), lo cual facilita la aceptación de este tipo de herramientas como sistemas de apoyo en la toma de decisiones \cite{Curti2024}.

La revisión de \textbf{Anisuzzaman } también resalta desarrollos en sistemas integrales para el cuidado de heridas. Por ejemplo, se han creado aplicaciones móviles que, apoyadas en redes neuronales, permiten al profesional tomar una foto de la úlcera con el teléfono y obtener instantáneamente mediciones de área y sugerencias sobre el tejido predominante \cite{https://doi.org/10.48550/arxiv.2009.07141}. También existen prototipos de dispositivos portátiles específicos para clínicas de heridas, que combinan cámaras especializadas (incluso 3D) con software de análisis para ofrecer un seguimiento cuantitativo de la cicatrización. Muchos de estos están en etapas de evaluación piloto, pero muestran la \textbf{tendencia} clara hacia la digitalización y automatización en la gestión de heridas crónicas. La IA, en conjunto con la disponibilidad cada vez mayor de cámaras de alta calidad en dispositivos móviles, habilita posibilidades como telemedicina en el cuidado de heridas (evaluar remotamente una herida a través de una foto enviada y analizada con algoritmos), o sistemas de alerta temprana que identifiquen si una herida está empeorando para recomendar consulta médica prioritaria. En resumen, las aplicaciones de IA en imágenes de heridas abarcan desde la segmentación precisa y objetiva de la herida hasta la predicción inteligente de índices clínicos de cicatrización, y representan un campo en rápida expansión dentro de la informática médica.

\subsection{Técnicas de segmentación y clasificación de tejidos en la herida}

Un componente esencial para estimar el estado de una herida crónica es \textbf{determinar la composición de su lecho}, es decir, qué proporción corresponde a tejido de granulación viable, cuánto es tejido necrótico o desvitalizado, y cuánto es epitelio nuevo en formación. Estos parámetros ofrecen información directa sobre la fase de cicatrización en la que se encuentra la úlcera: por ejemplo, un aumento del tejido de granulación rojo y brillante junto con la aparición de bordes epiteliales suele indicar progreso hacia la curación, mientras que la presencia predominante de tejido necrótico (fibrina amarilla o escara negra) señala estancamiento y riesgo de infección \cite{ulcerasCicatrizacixF3nxDAlcerasnet}. Por ello, las guías clínicas y herramientas de evaluación de heridas (como BWAT o PWAT) incluyen la estimación visual del porcentaje de cada tipo de tejido como un \textbf{indicador del estado de la herida}. La \textbf{granulación} se identifica típicamente por su aspecto rojizo húmedo (tejido nuevo con capilares abundantes), la \textbf{necrosis} por zonas de color amarillo, gris o negro (tejido muerto que el cuerpo no ha eliminado), y la \textbf{epitelización} por parches rosados claros en los bordes o islas en el interior (piel nueva en formación). Un seguimiento cuidadoso de estos componentes en el tiempo permite inferir si la herida avanza o retrocede en su proceso de reparación. 

La \textbf{segmentación automática} de los tejidos de una herida a partir de imágenes es técnicamente compleja debido a la variabilidad visual de las heridas (colores, texturas) y a factores de la imagen (iluminación, contraste). Los primeros intentos en este campo se basaron en técnicas tradicionales de \textbf{procesamiento digital de imágenes}. Entre ellas se cuentan los algoritmos de \textbf{segmentación por umbral y color}, donde se convertía la imagen a un espacio de color adecuado (por ejemplo CIELab) y se aplicaban umbrales para separar regiones rojas, amarillas, negras, etc. correspondientes a granulación, fibrina o escara. También se exploraron métodos de \textbf{segmentación por superpíxeles y crecimiento de regiones}, en los cuales la imagen se subdivide en pequeñas regiones homogéneas que luego se agrupan según similitud de color/textura para identificar distintas zonas de tejido. Adicionalmente, se diseñaron \textbf{sistemas expertos basados en reglas}, donde mediante conocimiento de especialistas se programaban criterios (p.ej., “si la región es roja brillante con cierta saturación, clasificar como granulación”). Estos enfoques no requieren datos de entrenamiento extensos, apoyándose en heurísticas fijas, y en algunos casos lograron resultados razonables en escenarios controlados. No obstante, enfrentan dificultades para generalizar: las heridas reales presentan gran diversidad y las condiciones de las fotos pueden cambiar (iluminación, presencia de gasas, sangrado, etc.), por lo que las reglas rígidas a menudo fallan fuera de un conjunto limitado de casos. 

Con el advenimiento del \textit{deep learning}, la segmentación de tejidos en heridas ha dado un salto en precisión y robustez. Las \textbf{redes neuronales convolucionales (CNN)} especializadas en segmentación semántica (como \textbf{U-Net, SegNet, DeepLab}, entre otras) se entrenan con conjuntos de imágenes de heridas donde cada pixel está etiquetado según el tipo de superficie que representa (fondo, herida, granulación, necrosis, epitelio, etc.). Estos modelos aprenden características visuales de alto nivel que distinguen automáticamente las regiones de interés. Un enfoque común es utilizar arquitecturas de \textbf{multi-tarea}, en que una misma red puede sacar varios mapas de salida: uno para segmentar la herida completa (frente a la piel intacta) y otro para segmentar dentro de la herida los diferentes tejidos. Esto es posible porque los distintos tipos de tejido en el lecho son excluyentes (una zona de la herida o es granulación, o es necrosis, etc.), y la red puede distribuir su capacidad en reconocer cada categoría. Los estudios indican que las CNN bien entrenadas pueden \textbf{clasificar píxeles de la herida en categorías de tejido con alta velocidad y exactitud}, superando a los algoritmos basados en umbrales en consistencia. Por ejemplo, como se mencionó antes, la aplicación de U-Net por Chairat  logró identificar correctamente la mayor parte de las áreas de granulación en las imágenes de prueba.

Pese a los progresos, \textbf{segmentar ciertos tejidos sigue siendo un desafío notable}. En particular, las áreas de \textbf{tejido necrótico} suelen ser pequeñas comparadas con el tamaño total de la herida y presentan alta variabilidad (desde costras duras negras hasta material viscoso amarillo), dificultando su reconocimiento consistente por el algoritmo. Incluso con modelos avanzados, los resultados de segmentación para necrosis son significativamente inferiores a los de tejidos como granulación. Chairat  reportaron IoU por debajo de 0,2 para la categoría "necrosis", alineado con otros estudios previos que igualmente encontraron bajos desempeños al segmentar tejido necrótico o esfacelos. Esto se atribuye a varios factores: desequilibrio de clases (pocas muestras de necrosis en los datos de entrenamiento en comparación con abundantes zonas de granulación), la dificultad intrínseca de distinguir visualmente necrosis cubierta de fibrina vs. fondo, y en parte la subjetividad en delinear qué se considera exactamente necrosis (los criterios pueden variar entre médicos, complicando el entrenamiento supervisado). De forma similar, la segmentación del área de epitelización suele presentar desempeño moderado, ya que este tejido nuevo aparece como parches muy delgados en los bordes, a veces difíciles de discernir incluso para el ojo humano y frecuentemente ausentes en estadios tempranos (por lo tanto poco representados en los datos). 

Otra arista crítica es la obtención de las etiquetas de entrenamiento para estos modelos. Requiere que especialistas tracen a mano, sobre cientos de imágenes, contornos precisos de cada tipo de tejido – una tarea ardua y propensa a discrepancias. Estudios han demostrado que la concordancia entre diferentes expertos al segmentar manualmente los tejidos de una herida puede ser limitada. Howell , por ejemplo, encontraron variaciones considerables entre profesionales al identificar las características de una herida en fotografías, reflejando la naturaleza subjetiva del proceso. En el trabajo de Chairat , fue necesario realizar múltiples rondas de discusión y hasta votaciones ciegas entre dermatólogos para acordar un \textit{ground truth} coherente antes de entrenar la red. Por tanto, la validación de las técnicas de segmentación de tejidos debe considerar esta variabilidad: un rendimiento “perfecto” del algoritmo comparado contra la etiqueta de un único experto podría aun así discrepar de la opinión de otro experto. Idealmente, las anotaciones de entrenamiento y prueba se obtienen con consenso de varios especialistas para mitigar el sesgo individual. En resumen, las técnicas modernas permiten abordar la segmentación y clasificación de tejidos en imágenes de heridas de forma automática. La combinación de calibración de imagen, algoritmos de segmentación profunda y un cuidadoso etiquetado experto ha dado lugar a sistemas capaces de identificar las porciones de granulación, necrosis y epitelio con una precisión útil clínicamente. No obstante, persisten áreas de mejora, especialmente en refinar la detección de los tejidos minoritarios y en disponer de bases de datos más amplias y estandarizadas para entrenar/validar estos algoritmos.


\subsection{Validación y desafíos en el uso de IA para la evaluación de heridas}

Si bien los resultados iniciales de la IA en evaluación de heridas son prometedores, su \textbf{traslado a la práctica clínica} enfrenta diversos desafíos que deben ser considerados en el marco conceptual de este proyecto. Uno de los desafíos principales es la \textbf{validación clínica y la confiabilidad} de estas herramientas. A diferencia de aplicaciones puramente técnicas, aquí se trata de sistemas que apoyarían decisiones médicas, por lo que requieren un alto grado de confianza. Esto implica evaluar rigurosamente su desempeño no solo en términos de métricas de imagen (IoU, exactitud de clasificación), sino también en resultados clínicamente relevantes (ej. capacidad para predecir qué heridas no cicatrizarán sin intervención, o concordancia con los juicios de expertos humanos). En este sentido, un obstáculo es la mencionada \textbf{subjetividad del “gold standard”}: la IA típicamente aprende a imitar las evaluaciones humanas, pero cuando estas evaluaciones humanas varían entre profesionales, ¿contra cuál se valida el modelo? Estudios han reportado que la concordancia inter-observador en evaluación de heridas es limitada, con diferencias apreciables en mediciones manuales de tamaño y apreciación de tejido. Esto dificulta definir un punto de referencia firme. Una estrategia para paliar ello, utilizada por Chairat y otros, es involucrar a múltiples expertos en la anotación y utilizar métodos de consenso (votación, promedios) para las etiquetas finales \cite{healthcare11020273}. Aun así, al validar el modelo, es recomendable comparar sus salidas con la opinión de varios especialistas y no de uno solo, para asegurarse de que la herramienta automatizada produzca resultados dentro del rango aceptado por la comunidad clínica. 

Otro desafío es la \textbf{disponibilidad de datos}. Los algoritmos de \textit{deep learning} suelen necesitar un volumen considerable de ejemplos para generalizar bien. En el dominio de heridas, sin embargo, los conjuntos de datos públicos son escasos y relativamente pequeños (a menudo decenas de imágenes, pocas superan el centenar). Además, muchos de ellos solo incluyen la segmentación de área total de la herida y no la anotación de tejidos internos. La recolección de un gran dataset de imágenes de heridas con anotaciones detalladas es complicada por varias razones: protección de datos de pacientes (imágenes clínicas sensibles), variabilidad de presentaciones (se necesitarían casos de pie diabético neuropático, isquémico, mixto; úlceras en distintos estadios; diversas etnias y tonos de piel, etc. para evitar sesgos), y el \textbf{coste en tiempo de los expertos} para etiquetar cada imagen. Este cuello de botella de datos hace que muchos modelos se entrenen con data limitada, corriendo riesgo de sobreajustarse a casos particulares y no rendir bien con imágenes de otros entornos. Incluso el modelo de Curti \cite{Curti2024}, que tuvo buen desempeño, se entrenó y validó con imágenes de un único centro (dataset \textit{DeepSkin} de Italia), lo que deja interrogante sobre su generalización a poblaciones distintas. Por tanto, un reto continuo es \textbf{ampliar y diversificar los datos} de entrenamiento, e idealmente compartir conjuntos de datos de heridas a nivel internacional para impulsar desarrollos más robustos. 

La \textbf{variabilidad en las condiciones de adquisición de las imágenes} es otra fuente de desafíos. A diferencia de otras imágenes médicas (radiografías, TAC) que son bastante estandarizadas, las fotografías de heridas pueden tomarse con diferentes dispositivos (distintos modelos de smartphones o cámaras), bajo variadas condiciones de iluminación ambiente, a distintas distancias o ángulos, etc. Esto impacta directamente en el rendimiento de los algoritmos de visión por computador. Por ejemplo, un modelo entrenado mayoritariamente con imágenes bien iluminadas podría fallar al evaluar una foto tomada en una habitación con poca luz o con luz artificial amarillenta. Chairat reportan que \textbf{diferencias en la iluminación y calibración de color} entre imágenes pueden reducir la precisión de segmentación, ya que los colores del tejido se perciben alterados \cite{healthcare11020273}. Para mitigar este problema, ellos incorporaron una carta de color y tamaño en cada foto, y demostraron que aplicar una \textbf{calibración automática} (ajustando los valores de color de la imagen para que coincidan con los del patrón conocido de la carta) aumentó significativamente las métricas de desempeño del modelo. Este enfoque de normalizar las imágenes es clave para que la IA no dependa de las condiciones específicas de cada foto. Sin embargo, en entornos reales no siempre será posible usar una carta calibradora; por ello, se investiga también que los modelos aprendan a ser invariables a ciertos cambios (por ejemplo, usando técnicas de \textit{data augmentation} que simulen distintas iluminaciones durante el entrenamiento). Otro aspecto es la \textbf{estimación de la profundidad de la herida} a partir de imágenes 2D: esto es prácticamente imposible de forma precisa sin asistencia, y es un parámetro crítico (pues define si una úlcera es superficial o compromete planos profundos). Algunas propuestas para abordar esto incluyen utilizar cámaras con sensor de profundidad o técnicas de fotogrametría para reconstruir un modelo 3D de la herida. Chairat mencionan planes de emplear cámaras 3D de tipo \textit{depth sensor} para captar la estructura volumétrica, o desarrollar dispositivos portátiles que incorporen la IA y sensores en la cabecera del paciente. Si bien esto añade complejidad tecnológica, podría solventar la limitación de las fotos comunes que “aplanan” la información. 

La \textbf{robustez y longevidad} de los algoritmos en el tiempo es otra consideración de validación. Un sistema automático ideal no solo debe funcionar en un solo análisis aislado, sino que debería servir para \textbf{seguimiento longitudinal} de la herida. Es decir, si se toman fotos semanales de una úlcera para ver su progreso, el algoritmo debe ser consistente en sus mediciones a lo largo del tiempo (por ejemplo, si calcula 20\% de necrosis un día y 10\% una semana después, uno espera que ese cambio refleje una realidad y no variaciones aleatorias de la IA). Evaluar la estabilidad longitudinal requiere pruebas específicas, aplicando el modelo en secuencias de tiempo conocidas y verificando que las tendencias que arroja concuerdan con la expectativa clínica. Asimismo, la robustez implica que pequeños cambios irrelevantes (ej., la presencia de una regla desechable al lado de la herida en una foto, o una gasa de fondo) no deberían alterar drásticamente el output del modelo. Muchos de estos aspectos se están abordando mediante técnicas de augmentación, entrenamiento con variedad de escenarios, y módulos de atención en las redes que enfoquen la herida e ignoren contexto no importante. 

Finalmente, existe el desafío de la aceptación e \textbf{integración clínica}. Desde el punto de vista de validación, no basta con demostrar en artículos científicos que un algoritmo funciona; es necesario que las herramientas se integren en el flujo de trabajo real de los profesionales de salud. Esto implica consideraciones de \textbf{interfaz de usuario}, interoperabilidad con historiales clínicos electrónicos, formación del personal, y evidencia de costo-efectividad. Por ejemplo, un algoritmo que provea un puntaje PWAT automatizado debe presentarlo de forma comprensible y útil para el clínico (idealmente junto con la imagen marcada o porcentajes claros), y debe integrarse en la rutina sin añadir mucha carga. También es importante gestionar las expectativas: la IA debe ser vista como soporte a la decisión y no como reemplazo del juicio clínico. Para ganar confianza, algunos sistemas explican sus resultados resaltando las áreas de la imagen que más contribuyeron a la predicción (lo que se conoce como \textbf{IA explicable} o \textit{explainable AI}). En el campo de las heridas, esto podría significar señalar las regiones que la red considera necróticas vs. granulación, para que el médico corrobore visualmente si está de acuerdo. Todos estos factores forman parte de los desafíos para la adopción plena de la IA en la evaluación de heridas.




\section{Estado del Arte}
\label{sc:EA}


Las heridas crónicas, como las úlceras diabéticas del pie , representan un serio problema de salud mundial por su alta prevalencia y complicaciones. Se estima que entre un 19\% y 34\% de los pacientes diabéticos desarrollarán una úlcera de pie en su vida, con elevado riesgo de mala cicatrización, amputación de miembros inferiores e incluso reducción de la supervivencia \cite{Zhang2022}. Las úlceras por presión (escaras) y las úlceras venosas son otros tipos comunes de heridas crónicas, todas contribuyendo a costos sanitarios multimillonarios \cite{Wang2020,Sendilraj2024}. La evaluación clínica de estas lesiones suele basarse en la inspección visual y mediciones manuales, procesos sujetos a la experiencia del profesional y, por tanto, con variabilidad interobservador \cite{Curti2024}. Para estandarizar la valoración, se han propuesto escalas clínicas como \textbf{BWAT}, \textbf{PUSH} o la clasificación de \textbf{Wagner}, entre otras. Sin embargo, aplicarlas requiere tiempo y puede ser subjetivo. En la última década, la \textbf{inteligencia artificial} (IA) – especialmente técnicas de \textbf{machine learning} (ML) y \textbf{deep learning} (DL) – ha emergido como herramienta prometedora para automatizar la evaluación de heridas ulcerosas, buscando mayor objetividad, eficiencia y seguimiento continuo \cite{Sendilraj2024,Curti2024}.

A continuación, se presenta una revisión crítica de trabajos relevantes (2015–2025) sobre el uso de IA en la evaluación automática de heridas ulcerosas, con énfasis en pie diabético pero sin limitarse a este. Se abordan desarrollos en segmentación de imágenes (delimitación de la herida y análisis de tamaño), clasificación y gradación de severidad, análisis de tejidos en la herida, predicción de evolución de la cicatrización, así como enfoques multimodales. Se comparan metodologías, resultados, conjuntos de datos empleados, fortalezas, debilidades y posibles mejoras, organizando la información en secciones temáticas para facilitar su lectura.

\subsection{Escalas clínicas de evaluación de heridas}

En la práctica clínica, existen escalas estandarizadas para evaluar el estado y la evolución de heridas. Por ejemplo, \textbf{BWAT (Bates-Jensen Wound Assessment Tool)} consta de 13 ítems que evalúan características como:
\begin{enumerate}
    \item tamaño
    \item profundidad de la herida
    \item bordes
    \item presencia de socavamiento
    \item tipo de tejido necrotico
    \item cantidad de tejido necrotico
    \item cantidad de tejido de ganulacion
    \item cantidad de tejido de epilizacion
    \item tipo de exudado
    \item cantidad de exudad
    \item condicion de la piel peilesional - color
    \item condicion de la piel peilesional - edema
    \item condicion de la piel peilesional - induracion
    
\end{enumerate}
Cada ítem se puntúa de 1 (mejor situación) a 5 (peor), ofreciendo un puntaje total que cuantifica la gravedad de la herida. Debido a que varios ítems requieren examen directo (ej., medir profundidad o socavamientos manualmente), el \textbf{BWAT} tradicionalmente se aplica \textbf{en persona} durante la visita clínica . Esto dificulta su automatización posterior a partir de fotografías, pues algunas características no son discernibles solo con imágenes. Para solventar esa limitación, se introdujo la escala \textbf{PWAT} \cite{Curti2024}. 

El PWAT es una adaptación del BWAT que incluye solo un subconjunto de los ítems –aquellos inferibles directamente de una fotografía–, excluyendo por ejemplo la profundidad o socavamientos. Pese a ser más limitado, el PWAT ha demostrado \textbf{validez y robustez} en aplicaciones clínicas para seguimiento mediante imágenes . Otra escala común es la \textbf{PUSH (Pressure Ulcer Scale for Healing)}, diseñada por NPIAP para monitorizar la cicatrización de úlceras por presión, combinando medidas de área superficial de la herida, cantidad de exudado y tipo de tejido dominante en el lecho ulceroso (granulación, esfacelo/fibrina o epitelial). La PUSH genera un puntaje total que disminuye a medida que la herida cura, facilitando evaluar si una úlcera por presión está mejorando o no

En cuanto a clasificación de severidad, para las úlceras de pie diabético se emplea la \textbf{clasificación de Wagner}, de 6 niveles (0 a 5) que describen la profundidad y complicaciones de la lesión . Un Wagner 0 indica pie de riesgo sin ulceración; Wagner 1 es una úlcera superficial; Wagner 2 implica extensión a tendón, hueso o cápsula articular; Wagner 3 añade infección grave (ej. osteomielitis o absceso); Wagner 4 denota gangrena localizada (por isquemia/infección) en antepié o talón; y Wagner 5 es gangrena extensa de todo el pie, generalmente requiriendo amputación \cite{Girmaw2025}. Esta clasificación guía el manejo clínico del pie diabético y pronostica la necesidad de intervenciones mayores.

Aunque las escalas estandarizadas han reducido parcialmente la subjetividad, sigue habiendo variabilidad entre observadores al aplicarlas. Por ejemplo, dos médicos podrían discrepar en la estimación del porcentaje de tejido de granulación vs. esfacelo en un lecho ulceroso, afectando la puntuación BWAT. En efecto, la evaluación en forma de escalas Likert impone categorías que \textbf{fuerzan la cuantificación} de rasgos de la herida, pero la interpretación visual sigue siendo del clínico . Estudios reportan que persiste una variabilidad inter e intraobservador no desdeñable incluso utilizando herramientas estandarizadas . Esto ha motivado la investigación en sistemas automatizados que extraigan de imágenes métricas objetivas de la herida (dimensiones, tipos de tejido, etc.) para calcular o apoyar estas escalas. A continuación se revisan los avances en dichos sistemas basados en IA.

Segmentar una herida en una imagen consiste en delinear automáticamente el contorno de la lesión y separarla de la piel sana circundante. Es un paso fundamental, pues permite calcular la superficie de la úlcera, un parámetro clave para monitorear la cicatrización (una reducción del área a lo largo del tiempo suele indicar progreso) \cite{Wang2020}. La medición manual del área (ej., con reglas o calcos sobre la herida) es engorrosa, imprecisa y consume tiempo \cite{Filko2023}. Automatizar la segmentación permite obtener \textbf{medidas objetivas de forma rápida}, facilitando la documentación y seguimiento en historias clínicas electrónicas . 

\begin{itemize}
    \item \textbf{Enfoques tradicionales}
    \begin{itemize}
        \item Antes del auge del deep learning, se exploraron métodos de visión por computador clásica para segmentar heridas crónicas. Estos incluían técnicas como umbralización de color, detección de bordes, crecimiento de regiones y uso de clasificadores basados en características diseñadas manualmente. Por ejemplo, Wang \cite{Chemello2022} propusieron un método de dos etapas: primero se sobresegmenta la imagen en superpixels y se extraen múltiples descriptores de color y textura; luego, un conjunto de clasificadores SVM distingue superpixels de herida vs. piel . Este clasificador en cascada logró sensibilidad $\sim73.3\%$ y especificidad $\sim94.6\%$ en segmentar úlceras diabéticas (100 imágenes de 15 pacientes) , superando a enfoques de una sola etapa o redes neuronales poco profundas probadas en esa cohorte. Posteriormente, Wang \cite{Chemello2022}  abordaron el reto de la variabilidad en condiciones de captura (iluminación, ángulo, fondo) entrenando un modelo de Random Field jerárquico (AHRF) que extendía los Conditional Random Fields. Probado en un conjunto pequeño de imágenes sintéticas y reales, este modelo logró especificidad >95\% y sensibilidad >77\% , mostrando mejor desempeño que CRFs tradicionales. Los autores sugirieron que en escenarios con muy pocos datos, modelos probabilísticos como AHRF podrían superar a CNNs profundas, aunque anticiparon que con más datos las redes neuronales lograrían resultados superiores .
    \end{itemize}
    \item \textbf{Deep learning en segmentación}
    \begin{itemize}
        \item A medida que aumentaron los conjuntos de datos de heridas, los métodos de deep learning demostraron ventajas claras en segmentación. Diversos arquitecturas de segmentación semántica han sido aplicadas: Fully Convolutional Networks, U-Net, SegNet, etc. Ohura evaluaron redes para segmentar úlceras combinando datos de distintos tipos de heridas: entrenaron CNNs (SegNet, LinkNet, U-Net) principalmente con 400 imágenes de úlceras por presión y apenas 20 imágenes de UPD \cite{Chemello2022}. Sorprendentemente, la U-Net logró altísima precisión al segmentar incluso las úlceras diabéticas (especificidad 0.943 y sensibilidad 0.993 en promedio) , evidenciando que patrones aprendidos en úlceras por presión podían transferirse a otras etiologías crónicas con morfologías parecidas. Este resultado sugirió que, dadas suficientes imágenes de entrenamiento, las redes profundas segmentan heridas con fiabilidad casi humana
        
        \item Varios grupos han construido sus propios datasets para entrenar modelos. Wang \cite{Wang2020} compilaron 1109 imágenes de úlceras de pie diabético de 889 pacientes y entrenaron un modelo basado en MobileNetV2 para segmentación automática . Eligiendo MobileNetV2 por su ligereza, demostraron que un modelo de baja complejidad podía lograr un rendimiento equiparable a redes más profundas en esa tarea . La arquitectura propuesta combinaba la segmentación por CNN con un post-procesamiento de componentes conexos para afinar la máscara final . Gracias a su menor costo computacional, este enfoque apuntaba a implementaciones en dispositivos móviles sin sacrificar precisión. De hecho, otras investigaciones también resaltan la factibilidad de ejecutar modelos de segmentación en smartphones: Ramachandram \cite{Ramachandram2022} entrenaron modelos U-Net con el mayor conjunto publicado hasta la fecha ($\approx465$ mil pares de imagen-máscara para segmentar heridas, más 17 mil para segmentar tejidos dentro de la herida) obtenidos de la base de datos de la compañía Swift Medical . El modelo resultante segmenta en tiempo casi real en un teléfono, dada la optimización lograda con ese enorme dataset . En pruebas, su red alcanzó un IoU promedio de 0,8644 delimitando el área de la herida (muy alto acuerdo con el contorno verdadero). Incluso en condiciones de iluminación y piel variadas, la segmentación automática mostró ser robusta y sin sesgos por tono de piel – un aspecto importante para equidad clínica

        \item La precisión de la segmentación profunda se refleja también en desafíos internacionales. En la competencia Diabetic Foot Ulcer Challenge (DFUC2020), múltiples equipos aplicaron detectores y segmentadores basados en YOLO, Faster R-CNN y U-Net. Un resumen de Yap et al. reportó que las mejores refinaciones de YOLOv3 lograron $\sim 91.95\%$ de exactitud en detección de úlcera en imagen completa, y variantes de Faster R-CNN alcanzaron hasta 91.4\% mAP . Para segmentación semántica, arquitecturas tipo U-Net destacaron; en un estudio se informa que un modelo U-Net superó a otras arquitecturas con 94.96\% de precisión en segmentación de la herida . Asimismo, aplicando Mask RCNN (que combina detección y segmentación a nivel de instancia) se han logrado valores de precision $\sim 0.86$ y mAP $\sim 0.51$ segmentando úlceras . En suma, la comunidad ha validado que las CNN bien entrenadas pueden delimitar las heridas con alta fiabilidad, permitiendo calcular el área de forma automática y consistente
    \end{itemize}
    \item \textbf{Comparativa de enfoques de segmentación}
    \begin{itemize}
        \item Los métodos basados en DL superan a los clásicos en exactitud, especialmente cuando hay suficiente volumen de datos para entrenar. Los enfoques tradicionales (p. ej. SVM con atributos diseñados) alcanzaron especificidades altas en conjuntos pequeños , pero su sensibilidad quedaba limitada posiblemente por la variabilidad visual que no capturaban totalmente. Las CNN, al aprender características de bajo a alto nivel directamente de los píxeles, manejan mejor dicha variabilidad, logrando sensibilidades y especificidades cercanas al 90–99\% \cite{Chemello2022}. No obstante, un desafío común es la \textbf{generalización}: muchos estudios emplearon datos de un único centro o condiciones controladas, y un modelo puede perder precisión si se aplica a imágenes con distinta iluminación, dispositivos o poblaciones. Para mitigar esto, algunos autores integran pasos de pre-procesamiento de color (ej. conversión a espacios de color uniformes Lab, YCbCr) antes de la segmentación, como en la plataforma DFUCare \cite{Sendilraj2024}, o aplican extensas técnicas de \textit{data augmentation } \cite{Aldughayfiq2023} para expandir la diversidad de ejemplos de entrenamiento. Otra tendencia es combinar modalidades: Filko \cite{Filko2023} desarrollaron un sistema robótico que captura simultáneamente la herida en 2D (fotografía RGB) y en 3D mediante escaneo láser, usando una CNN 2D para segmentar inicialmente la herida en la imagen y luego refinando el contorno sobre la malla 3D con un modelo activo de contornos \cite{Filko2023}. Este enfoque híbrido produce un modelo 3D de la superficie herida, permitiendo medir \textbf{perímetro, área y volumen} de la úlcera de forma totalmente automática . La incorporación de volumen es valiosa, ya que una reducción volumétrica puede indicar curación antes que la reducción de área en ciertas lesiones profundas.
    \end{itemize}
\end{itemize}

\subsection{Clasificación de heridas: detección, severidad e infección}

Otra línea de aplicación de la IA en heridas es la clasificación automática, que puede tomar varias formas según el objetivo clínico:
\begin{itemize}
    \item \textbf{Detección vs. piel sana}
    \begin{itemize}
        \item Identificar si en una foto de un pie o de la piel hay una úlcera presente (clasificación binaria herida/no herida)
    \end{itemize}
    \item \textbf{Clasificación del tipo de herida}
    \begin{itemize}
        \item  Por etiología (diabética, venosa, por presión, quirúrgica, etc.) o por estadio (p. ej. estadios I–IV de úlcera por presión, grados Wagner 0–5 en pie diabético).
    \end{itemize}
    \item \textbf{Detección de signos clínicos en la herida}
    \begin{itemize}
        \item clasificar si una úlcera de pie diabético muestra signos de infección, de isquemia, ambas o ninguna (clasificación multinomial)
    \end{itemize}
    \item \textbf{Gradación de severidad}
    \begin{itemize}
        \item Asociada a escalas como Wagner, Texas, NPUAP, etc., a partir de la imagen.
    \end{itemize}
\end{itemize}

Varios trabajos han explorado redes neuronales para estas tareas de clasificación a nivel de imagen o de herida. En general, las arquitecturas de deep learning utilizadas son CNNs de clasificación (VGG, ResNet, EfficientNet, MobileNet, etc.) o detectores de objetos cuando se necesita localizar la herida en la foto además de clasificarla

\begin{itemize}
    \item \textbf{Detección de úlceras (binario sí/no)}
    \begin{itemize}
        \item Goyal \cite{Goyal2020} desarrollaron \textbf{DFUNet}, una arquitectura de CNN especializada en identificar regiones con úlcera vs piel normal en el pie diabético . DFUNet combinaba convoluciones profundas con capas paralelas y de distinta profundidad para captar características a múltiples escalas, logrando mejorar la discriminación entre piel sana y lesionada . Este trabajo pionero ya demostraba la viabilidad de deep learning para detectar automáticamente una úlcera en imágenes donde pudiera haber artefactos o variabilidad en los pies de pacientes diabéticos. Estudios posteriores han reportado precisiones muy altas en esta tarea: Cassidy \cite{Cassidy2023} hicieron un \textbf{estudio clínico multicéntrico} con 203 fotografías de pies tomadas con un smartphone de bajo costo, pasando cada imagen por un sistema de IA para detectar úlceras y comparando con la evaluación de especialistas. El modelo alcanzó \textbf{91.6\% de sensibilidad y 92.4\% de especificidad} en la detección de úlceras , prácticamente equiparable a la precisión humana. Es notable que incluso con imágenes capturadas en entornos reales (no de estudio), la IA mantuvo alto desempeño, lo cual avala su potencial uso como herramienta de tamizaje remoto. Los clínicos participantes mostraron además alto acuerdo (Kappa >0.8) en que el sistema identifica correctamente las úlceras . Este es uno de los primeros ensayos que prueban un algoritmo de visión computacional en campo con pacientes, marcando un hito hacia la adopción como dispositivo médico

        \item En escenarios más controlados, se han conseguido incluso accuracies cercanas a la perfección en detección binaria, aunque en conjuntos de datos limitados. Por ejemplo, Girmaw y Taye \cite{Girmaw2025} entrenaron un modelo MobileNetV2 para detectar la presencia de UPD y reportan \textbf{100\% de exactitud} en sus pruebas . Si bien este resultado es llamativo, es probable que su dataset no haya sido muy amplio ni diverso, lo que podría indicar cierto \textit{overfitting}. Aun así, refleja la capacidad de las CNN modernas: un modelo ligero fue suficiente para separar completamente imágenes con vs sin úlcera en el conjunto evaluado . Los autores destacan la importancia de la cuidadosa preparación de datos (anotaciones, aumentos, etc.) y ajuste de hiperparámetros para lograr tal rendimiento , subrayando que la clave está tanto en la arquitectura como en el \textit{fine-tuning} adecuado.
    \end{itemize}
        
\end{itemize}

